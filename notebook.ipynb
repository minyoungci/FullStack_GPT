{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```from langchain.chat_models import ChatOpenAI```\n",
    "\n",
    "chat_models의 ChatOpenAI 모델을 살펴보면 model_name: str = \"gpt-3.5-turbo\" 이렇게 되어있는데, 이는 gpt 3.5 turbo 모델을 사용한다는 뜻입니다.\n",
    "llms.openai는 model_name: str = \"text-davinci-003\" 이렇게 되어있습니다. \n",
    "\n",
    "openai 웹사이트에서(https://platform.openai.com/docs/models/gpt-3-5) 이 모델들의 차이점을 알아볼 수 있습니다. \n",
    "\n",
    "간단하게 둘을 비교해보자면 gpt 3.5 turbo는 text davinci 003 보다 chat에 특화되어 있습니다. 비용이 매우 저렴(1/10 수준)하기 때문입니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 호출 \n",
    "\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /home/minyoungxi/MINYOUNGXI/fullstack-gpt/env/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API가 통합되어 있어서 위의 langchain에서 사용하고 싶은 모델을 그대로 가져와서 사용할 수 있음. \n",
    "\n",
    "아래의 결과를 보면 대화형인 chatopenai 모델이 조금 더 대화 형식에 가까운 문장을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nThere are eight officially recognized planets in our Solar System: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.',\n",
       " 'As of now, there are eight confirmed planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat model은 단지 질문을 받을 수 있을 뿐만 아니라 대화를 할 수도 있다는 뜻입니다. \n",
    "\n",
    "만약 model의 설정을 바꾸고 싶다면 model의 constructor(생성자)를 통해 할 수 있습니다.\n",
    "\n",
    "ex1. max_tokens = model이 반환하는 결과의 최대 token을 정할 수 있음. \n",
    "ex2. temperature = model이 얼마나 창의적인지를 결정할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "predict messages는 위에서 본 것처럼 텍스트를 predict 하는 방법입니다. 질문을 하고 답변을 받는 방식이죠. 이번에는 messages들을 predict 할 것입니다. \n",
    "\n",
    "Humanmessage는 우리가 알고 있고, AIMessage는 AI가 보내는 메세지, SystemMessage는 우리가 LLM에 설정들을 제공하기 위한 Message입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao Paolo! La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "message = [\n",
    "    SystemMessage(content = \"You are a geography expert. And you only reply in Italian.\"),\n",
    "    AIMessage(content = \"Ciao ! mi chiamo Paolo\"),\n",
    "    HumanMessage(content='what is the distance between Mexico and Thailand. Also, what is your name?'),\n",
    "] \n",
    "\n",
    "chat.predict_messages(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates \n",
    "\n",
    "- more custome 해보자 ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

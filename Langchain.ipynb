{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```from langchain.chat_models import ChatOpenAI```\n",
    "\n",
    "chat_models의 ChatOpenAI 모델을 살펴보면 model_name: str = \"gpt-3.5-turbo\" 이렇게 되어있는데, 이는 gpt 3.5 turbo 모델을 사용한다는 뜻입니다.\n",
    "llms.openai는 model_name: str = \"text-davinci-003\" 이렇게 되어있습니다. \n",
    "\n",
    "openai 웹사이트에서(https://platform.openai.com/docs/models/gpt-3-5) 이 모델들의 차이점을 알아볼 수 있습니다. \n",
    "\n",
    "간단하게 둘을 비교해보자면 gpt 3.5 turbo는 text davinci 003 보다 chat에 특화되어 있습니다. 비용이 매우 저렴(1/10 수준)하기 때문입니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 호출 \n",
    "\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /home/minyoungxi/MINYOUNGXI/fullstack-gpt/env/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API가 통합되어 있어서 위의 langchain에서 사용하고 싶은 모델을 그대로 가져와서 사용할 수 있음. \n",
    "\n",
    "아래의 결과를 보면 대화형인 chatopenai 모델이 조금 더 대화 형식에 가까운 문장을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nThere are eight officially recognized planets in our Solar System: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.',\n",
       " 'As of now, there are eight confirmed planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat model은 단지 질문을 받을 수 있을 뿐만 아니라 대화를 할 수도 있다는 뜻입니다. \n",
    "\n",
    "만약 model의 설정을 바꾸고 싶다면 model의 constructor(생성자)를 통해 할 수 있습니다.\n",
    "\n",
    "ex1. max_tokens = model이 반환하는 결과의 최대 token을 정할 수 있음. \n",
    "ex2. temperature = model이 얼마나 창의적인지를 결정할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "predict messages는 위에서 본 것처럼 텍스트를 predict 하는 방법입니다. 질문을 하고 답변을 받는 방식이죠. 이번에는 messages들을 predict 할 것입니다. \n",
    "\n",
    "Humanmessage는 우리가 알고 있고, AIMessage는 AI가 보내는 메세지, SystemMessage는 우리가 LLM에 설정들을 제공하기 위한 Message입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao Paolo! La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "message = [\n",
    "    SystemMessage(content = \"You are a geography expert. And you only reply in Italian.\"),\n",
    "    AIMessage(content = \"Ciao ! mi chiamo Paolo\"),\n",
    "    HumanMessage(content='what is the distance between Mexico and Thailand. Also, what is your name?'),\n",
    "] \n",
    "\n",
    "chat.predict_messages(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates \n",
    "\n",
    "- Prompt는 LLM과 의사소통할 수있는 유일한 방법임.\n",
    "\n",
    "- more custome 해보자 ! \n",
    "\n",
    "- 아래의 코드를 통해 각 구성요소(components)를 잘 익혀보자 !! ( 나중에 어차피 한 라인으로 프롬프트와 템플릿을 사용할 수 있으니 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate , ChatPromptTemplate \n",
    "\n",
    "# PromptTemplate , ChatPromptTemplate  이 두 개의 프롬프트 템플릿은 다르다. \n",
    "# ChatPromptTemplate은 template을 message로부터 만듭니다. 반면 PromptTemplate은 String을 받아서 template을 만듭니다.\n",
    "\n",
    "# example \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}?\")\n",
    "\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict(prompt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Γεια σας! Το όνομά μου είναι MIN. Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 17.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao ! mi chiamo {name}\"),\n",
    "    (\n",
    "        \"human\", \n",
    "        \"what is the distance between {country_a} and {country_b}. Also, what is your name?\",\n",
    "    ),\n",
    "] )\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language=\"Greek\",\n",
    "    name=\"MIN\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\",\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
